{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35d271",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorboard as tb\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorboard.backend.event_processing import event_accumulator as ea\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26ae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take every X sample for plot (raw log interval: 20k frames) default: 6\n",
    "DATA_PLOT_SPARSITY = 6\n",
    "\n",
    "# rolling average sample window (applied after sparsity) default: 4\n",
    "DATA_PLOT_SMOOTHNESS = 4\n",
    "\n",
    "MAX_TRAINING_STEPS = 20000000\n",
    "\n",
    "# in and out dirs\n",
    "logs_dir = Path.home() / Path(\"ordner\", \"mthesis\", \"live_scobi_logs\", \"relogs\")\n",
    "out_dir = Path.cwd() / Path(\"plots\")\n",
    "\n",
    "# envs to look for in logdir and subdirs and plot\n",
    "envs = [\"pong\", \"boxing\", \"tennis\", \"bowling\", \"skiing\", \"freeway\"]\n",
    "\n",
    "# experiments to exclude from plots:\n",
    "dont_plot = []\n",
    "\n",
    "# scalars to look for in tfevent files and plot\n",
    "scalars_to_plot = {\"rewards/avg_return\":\n",
    "                       {\"title\" : \"Trajectory Return\",\n",
    "                        \"xlabel\": \"Frames (M)\",\n",
    "                        \"ylabel\": \"Score\"},\n",
    "                   \"various/avg_steps\":\n",
    "                       {\"title\" : \"Trajectory Length\",\n",
    "                        \"xlabel\": \"Frames (M)\",\n",
    "                        \"ylabel\": \"Steps\"},\n",
    "                  \"loss/avg_policy_net_entropy\":\n",
    "                       {\"title\" : \"Policy MLP Entropy\",\n",
    "                        \"xlabel\": \"Frames (M)\",\n",
    "                        \"ylabel\": \"Entropy\"},\n",
    "                  \"loss/avg_value_net\":\n",
    "                       {\"title\" : \"Value MLP Loss\",\n",
    "                        \"xlabel\": \"Frames (M)\",\n",
    "                        \"ylabel\": \"MSE\"}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa2a81c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e655e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc02439",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "def time_str(delta):\n",
    "    x = str(delta).split(\":\")\n",
    "    return f\"{x[0]}h {x[1]}m {x[2]}s\"\n",
    "    \n",
    "\n",
    "# for one env\n",
    "def get_dfs_for_env(env, sca2p, everyx=5, smooth_window=5):\n",
    "    exp_list = []\n",
    "    for p in logs_dir.rglob(\"*\"):\n",
    "        if p.is_file():\n",
    "            if env in str(p.parents[0].name):\n",
    "                split_name = p.parents[0].name.split(\"seed\")\n",
    "                seed = split_name[-1]\n",
    "                exp_name = split_name[0]\n",
    "                if p.parents[0].name in dont_plot:\n",
    "                    continue\n",
    "                exp_list.append((seed, p.parents[0]))\n",
    "    exp_list = set(exp_list) # remove duplicates\n",
    "    if len(exp_list) == 0:\n",
    "        return None\n",
    "    exp_str_list = \" \".join([str(n[0]) for n in exp_list])\n",
    "    \n",
    "    # {seed : [(tag, s.step, s.value, seed),...]}\n",
    "    data_dict = {}\n",
    "    seed_progress = [[],[]]\n",
    "    for seed, log_dir in exp_list: #TODO: plot bug found: logs split across multiple machine dirs\n",
    "        max_step  = 0\n",
    "        max_wt = 0\n",
    "        if \"pruned\" in log_dir.name:\n",
    "            scobi_mode = 1\n",
    "        else:\n",
    "            scobi_mode = 0\n",
    "        for file in log_dir.iterdir():\n",
    "            if 'tfevents' in file.name:\n",
    "                acc = ea.EventAccumulator(str(file))\n",
    "                acc.Reload()\n",
    "                scalar_list = acc.Tags()['scalars']                        \n",
    "                key = seed + \"_\" + str(scobi_mode)\n",
    "                for tag in scalar_list:\n",
    "                    for s in acc.Scalars(tag):\n",
    "                        if not key in data_dict.keys():\n",
    "                            data_dict[key] = []\n",
    "                        data_dict[key].append((tag, s.step, s.value, seed, scobi_mode, s.wall_time))\n",
    "                        max_step = s.step if max_step < s.step else max_step\n",
    "                        max_wt = s.wall_time if max_wt < s.wall_time else max_wt\n",
    "        seed_progress[scobi_mode].append((seed, (max_step +10000) / MAX_TRAINING_STEPS * 100, max_wt))\n",
    "    seed_progress[0] = sorted(seed_progress[0], key=lambda x: x[0])\n",
    "    seed_progress[1] = sorted(seed_progress[1], key=lambda x: x[0])\n",
    "    now = time.time()\n",
    "    \n",
    "    scobi_seeds_str = \"\\tscobi\\n\" + \"\\n\".join([f\"\\t\\t{x}\\t{y:.2f}%\\t\\t{time_str(timedelta(seconds=int(now-z)))} ago\" for x, y, z in seed_progress[0]])\n",
    "    iscobi_seeds_str = \"\\tiscobi\\n\" + \"\\n\".join([f\"\\t\\t{x}\\t{y:.2f}%\\t\\t{time_str(timedelta(seconds=int(now-z)))} ago\" for x, y, z in seed_progress[1]])\n",
    "    \n",
    "    print(f\"{env}\")\n",
    "    print(scobi_seeds_str)\n",
    "    print(iscobi_seeds_str)# \\t|\\tSeeds: scobi: {scobi_seeds_str} \\tiscobi: {iscobi_seeds_str}\")\n",
    "    # extracts scalar samples from df,\n",
    "    # processes them (skipping and smoothing)\n",
    "    # and appends them to dict value : {scalar_name : [scalar_df, ..]}\n",
    "    def scalars_to_df(df, scalars, out_df_dict):\n",
    "        for s in scalars:\n",
    "            scalar_df = df[df[\"tag\"] == s].copy()            \n",
    "            scalar_df = scalar_df.sort_values(by=[\"step\", \"wall_time\"], ascending=True)\n",
    "            scalar_df = scalar_df.drop_duplicates(subset=['step'], keep=\"last\")\n",
    "            scalar_df = scalar_df.iloc[::everyx, :]\n",
    "            scalar_df[\"value\"] = scalar_df.value.rolling(smooth_window, min_periods=1).mean()\n",
    "            if s in out_df_dict.keys():\n",
    "                out_df_dict[s].append(scalar_df)\n",
    "            else:\n",
    "                out_df_dict[s] = [scalar_df]\n",
    "    \n",
    "    scalar_dict = {}    \n",
    "    # {scalar_name : [scalar_df_seedX, ..],\n",
    "    #  scalar_name2 : [scalar_df_seedX, ..]}\n",
    "    for k, v in data_dict.items():\n",
    "        df = pd.DataFrame(v, columns=[\"tag\", \"step\", \"value\", \"seed\", \"scobi_mode\", \"wall_time\"])\n",
    "        df.step = df.step / 1000000\n",
    "        scalars_to_df(df, sca2p, scalar_dict)\n",
    "\n",
    "    # merge seed df's of one scalar to one df, inplace\n",
    "    scalar_dict.update((k, pd.concat(v, ignore_index=True)) for k, v in scalar_dict.items())\n",
    "    return scalar_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c38bf3",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "data_to_plot = {}\n",
    "\n",
    "# goes over every specified env and\n",
    "# creates dict: {env : {scalar1 : df, scalar2 : df, ...}, env2 : {scalar1 : df, scalar2 :df, ...}, ...}\n",
    "print(\"env\\tmode\\tseed\\tprogress\\tlast log update\")\n",
    "for e in envs:\n",
    "    res_dict = get_dfs_for_env(e, scalars_to_plot.keys(), DATA_PLOT_SPARSITY, DATA_PLOT_SMOOTHNESS)\n",
    "    if res_dict:\n",
    "        data_to_plot[e] = res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dbfed7",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "fig_width = 20\n",
    "no_envs = len(data_to_plot)\n",
    "no_scalars = len(scalars_to_plot)\n",
    "width_per_plot = fig_width / no_scalars\n",
    "fig_size = (fig_width, no_envs * width_per_plot)\n",
    "fig = plt.figure(figsize=fig_size, dpi=150)\n",
    "subfigs = fig.subfigures(no_envs, 1)\n",
    "# env interator\n",
    "for i, (k, v) in enumerate(data_to_plot.items()):\n",
    "    subfigs[i].suptitle(str(k), fontsize=22, y=1)\n",
    "    axes = subfigs[i].subplots(1, no_scalars)\n",
    "    # scalar iterator\n",
    "    for j, (s_name, s_descriptions) in enumerate(scalars_to_plot.items()):\n",
    "        order = sorted(v[s_name][\"scobi_mode\"].unique())\n",
    "        s_plt = sns.lineplot(data=v[s_name], x=\"step\", y=\"value\", hue=\"scobi_mode\", hue_order=order, ax=axes[j])\n",
    "        axes[j].get_legend().remove()\n",
    "        s_plt.set(\n",
    "            xlabel = s_descriptions[\"xlabel\"],\n",
    "            ylabel = s_descriptions[\"ylabel\"],\n",
    "            title  = s_descriptions[\"title\"])\n",
    "\n",
    "plt.subplots_adjust(top = 0.9, bottom=0.15, left=0, right=1)\n",
    "plt.show(fig)\n",
    "fig.savefig(out_dir / \"results.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce85077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189ba86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a752d587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
